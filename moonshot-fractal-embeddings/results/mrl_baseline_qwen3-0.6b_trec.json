{
  "method": "mrl_baseline",
  "model": "qwen3-0.6b",
  "dataset": "trec",
  "baseline": {
    "l0_accuracy": 0.834,
    "l1_accuracy": 0.698
  },
  "mrl": {
    "l0_accuracy": 0.936,
    "l1_accuracy": 0.818
  },
  "delta": {
    "l0": 0.10200000000000009,
    "l1": 0.12
  },
  "prefix_accuracy": {
    "j1_l0": 0.942,
    "j1_l1": 0.816,
    "j2_l0": 0.94,
    "j2_l1": 0.814,
    "j3_l0": 0.936,
    "j3_l1": 0.822,
    "j4_l0": 0.936,
    "j4_l1": 0.818
  },
  "history": [
    {
      "stage": 1,
      "epoch": 1,
      "loss": 6.140283989084178,
      "loss_full": 3.683970831180441,
      "loss_mrl": 4.0938551047752645,
      "l0_accuracy": 0.8333333333333334,
      "l1_accuracy": 0.6942355889724311
    },
    {
      "stage": 1,
      "epoch": 2,
      "loss": 3.861596885220758,
      "loss_full": 2.296731692963633,
      "loss_mrl": 2.6081085270848767,
      "l0_accuracy": 0.8421052631578947,
      "l1_accuracy": 0.7243107769423559
    },
    {
      "stage": 1,
      "epoch": 3,
      "loss": 2.8989959642804903,
      "loss_full": 1.7273286618035415,
      "loss_mrl": 1.9527787594959654,
      "l0_accuracy": 0.8421052631578947,
      "l1_accuracy": 0.7393483709273183
    },
    {
      "stage": 1,
      "epoch": 4,
      "loss": 2.144260176296892,
      "loss_full": 1.2721078843906009,
      "loss_mrl": 1.4535870917912188,
      "l0_accuracy": 0.8508771929824561,
      "l1_accuracy": 0.7468671679197995
    },
    {
      "stage": 1,
      "epoch": 5,
      "loss": 1.7251975322591848,
      "loss_full": 1.0269908936886951,
      "loss_mrl": 1.163677685219666,
      "l0_accuracy": 0.8483709273182958,
      "l1_accuracy": 0.7343358395989975
    }
  ],
  "training_config": {
    "prefix_probs": [
      0.4,
      0.3,
      0.2,
      0.1
    ],
    "block_keep_probs": [
      0.95,
      0.9,
      0.8,
      0.7
    ],
    "mrl_weight": 0.6,
    "margin_weight": 0.5,
    "class_weight": 1.0,
    "stage1_epochs": 5,
    "stage2_epochs": 0,
    "batch_size": 16,
    "lr": 0.0001,
    "weight_decay": 0.01,
    "temperature": 0.07,
    "grad_clip": 1.0,
    "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
  }
}