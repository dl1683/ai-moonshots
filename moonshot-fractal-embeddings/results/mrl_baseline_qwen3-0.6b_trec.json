{
  "method": "mrl_baseline",
  "model": "qwen3-0.6b",
  "dataset": "trec",
  "baseline": {
    "l0_accuracy": 0.834,
    "l1_accuracy": 0.698
  },
  "mrl": {
    "l0_accuracy": 0.926,
    "l1_accuracy": 0.832
  },
  "delta": {
    "l0": 0.09200000000000008,
    "l1": 0.134
  },
  "prefix_accuracy": {
    "j1_l0": 0.94,
    "j1_l1": 0.834,
    "j2_l0": 0.938,
    "j2_l1": 0.832,
    "j3_l0": 0.934,
    "j3_l1": 0.838,
    "j4_l0": 0.926,
    "j4_l1": 0.832
  },
  "history": [
    {
      "stage": 1,
      "epoch": 1,
      "loss": 6.184512957211198,
      "loss_full": 3.6886502089171573,
      "loss_mrl": 4.159771059299337,
      "l0_accuracy": 0.8220551378446115,
      "l1_accuracy": 0.6992481203007519
    },
    {
      "stage": 1,
      "epoch": 2,
      "loss": 3.8611882139896525,
      "loss_full": 2.2870775987362038,
      "loss_mrl": 2.6235175864449864,
      "l0_accuracy": 0.8446115288220551,
      "l1_accuracy": 0.7180451127819549
    },
    {
      "stage": 1,
      "epoch": 3,
      "loss": 2.8916374946462695,
      "loss_full": 1.713557143663538,
      "loss_mrl": 1.9634671605866532,
      "l0_accuracy": 0.8621553884711779,
      "l1_accuracy": 0.7543859649122807
    },
    {
      "stage": 1,
      "epoch": 4,
      "loss": 2.193443017170347,
      "loss_full": 1.301294275193379,
      "loss_mrl": 1.4869145023411718,
      "l0_accuracy": 0.8609022556390977,
      "l1_accuracy": 0.7631578947368421
    },
    {
      "stage": 1,
      "epoch": 5,
      "loss": 1.7710974744681653,
      "loss_full": 1.051839987676719,
      "loss_mrl": 1.1987624271162625,
      "l0_accuracy": 0.8696741854636592,
      "l1_accuracy": 0.7619047619047619
    }
  ],
  "training_config": {
    "prefix_probs": [
      0.4,
      0.3,
      0.2,
      0.1
    ],
    "block_keep_probs": [
      0.95,
      0.9,
      0.8,
      0.7
    ],
    "mrl_weight": 0.6,
    "margin_weight": 0.5,
    "class_weight": 1.0,
    "stage1_epochs": 5,
    "stage2_epochs": 0,
    "batch_size": 16,
    "lr": 0.0001,
    "weight_decay": 0.01,
    "temperature": 0.07,
    "grad_clip": 1.0,
    "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
  }
}