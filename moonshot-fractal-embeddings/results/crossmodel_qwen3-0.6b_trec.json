{
  "dataset": "trec",
  "model": "qwen3-0.6b",
  "seeds": [
    42,
    123,
    456
  ],
  "v5": {
    "42": {
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "v5": {
        "l0_accuracy": 0.928,
        "l1_accuracy": 0.812
      },
      "delta": {
        "l0": 0.09400000000000008,
        "l1": 0.1140000000000001
      },
      "prefix_accuracy": {
        "j1_l0": 0.956,
        "j1_l1": 0.754,
        "j2_l0": 0.95,
        "j2_l1": 0.808,
        "j3_l0": 0.934,
        "j3_l1": 0.814,
        "j4_l0": 0.928,
        "j4_l1": 0.812
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.414060570453775,
          "loss_full": 3.5731828105860743,
          "loss_prefix": 3.0681294852289662,
          "l0_accuracy": 0.8483709273182958,
          "l1_accuracy": 0.7055137844611529
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.6915732556375964,
          "loss_full": 2.2350939964425973,
          "loss_prefix": 2.427465346763874,
          "l0_accuracy": 0.8609022556390977,
          "l1_accuracy": 0.7180451127819549
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.8957601206056003,
          "loss_full": 1.626649359176899,
          "loss_prefix": 2.115184508932048,
          "l0_accuracy": 0.868421052631579,
          "l1_accuracy": 0.7355889724310777
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.4036038184988087,
          "loss_full": 1.2645921578695034,
          "loss_prefix": 1.89835269492248,
          "l0_accuracy": 0.8583959899749374,
          "l1_accuracy": 0.7456140350877193
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 2.003124378878495,
          "loss_full": 0.9882398422422081,
          "loss_prefix": 1.6914741602437249,
          "l0_accuracy": 0.8659147869674185,
          "l1_accuracy": 0.7543859649122807
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "123": {
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "v5": {
        "l0_accuracy": 0.952,
        "l1_accuracy": 0.818
      },
      "delta": {
        "l0": 0.118,
        "l1": 0.12
      },
      "prefix_accuracy": {
        "j1_l0": 0.95,
        "j1_l1": 0.748,
        "j2_l0": 0.954,
        "j2_l1": 0.81,
        "j3_l0": 0.954,
        "j3_l1": 0.82,
        "j4_l0": 0.952,
        "j4_l1": 0.818
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.446461600270765,
          "loss_full": 3.623592658700614,
          "loss_prefix": 3.0381147680611447,
          "l0_accuracy": 0.8421052631578947,
          "l1_accuracy": 0.6892230576441103
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.6858592913068575,
          "loss_full": 2.2555815248653808,
          "loss_prefix": 2.3837961842273843,
          "l0_accuracy": 0.8421052631578947,
          "l1_accuracy": 0.7142857142857143
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.865321795282693,
          "loss_full": 1.6101549160891566,
          "loss_prefix": 2.0919447109617035,
          "l0_accuracy": 0.8483709273182958,
          "l1_accuracy": 0.7205513784461153
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.391147636134049,
          "loss_full": 1.2592992953185378,
          "loss_prefix": 1.8864138192143933,
          "l0_accuracy": 0.8696741854636592,
          "l1_accuracy": 0.7518796992481203
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 2.0335050895296294,
          "loss_full": 1.007052265159015,
          "loss_prefix": 1.7107546436375585,
          "l0_accuracy": 0.8621553884711779,
          "l1_accuracy": 0.7468671679197995
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "456": {
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "v5": {
        "l0_accuracy": 0.95,
        "l1_accuracy": 0.824
      },
      "delta": {
        "l0": 0.11599999999999999,
        "l1": 0.126
      },
      "prefix_accuracy": {
        "j1_l0": 0.966,
        "j1_l1": 0.75,
        "j2_l0": 0.956,
        "j2_l1": 0.802,
        "j3_l0": 0.95,
        "j3_l1": 0.828,
        "j4_l0": 0.95,
        "j4_l1": 0.824
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.502217177687021,
          "loss_full": 3.6801570571702102,
          "loss_prefix": 3.036766776956361,
          "l0_accuracy": 0.8421052631578947,
          "l1_accuracy": 0.6979949874686717
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.72276750186394,
          "loss_full": 2.251184110805906,
          "loss_prefix": 2.4526388867148037,
          "l0_accuracy": 0.8521303258145363,
          "l1_accuracy": 0.7293233082706767
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.920542931967768,
          "loss_full": 1.6587125155432472,
          "loss_prefix": 2.1030506072373227,
          "l0_accuracy": 0.8571428571428571,
          "l1_accuracy": 0.731829573934837
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.3613327671741615,
          "loss_full": 1.235252940243688,
          "loss_prefix": 1.876799632351974,
          "l0_accuracy": 0.8646616541353384,
          "l1_accuracy": 0.7330827067669173
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 1.996407305783239,
          "loss_full": 0.9928031017040384,
          "loss_prefix": 1.6726735970069622,
          "l0_accuracy": 0.8609022556390977,
          "l1_accuracy": 0.7493734335839599
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    }
  },
  "mrl": {
    "42": {
      "method": "mrl_baseline",
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "mrl": {
        "l0_accuracy": 0.924,
        "l1_accuracy": 0.832
      },
      "delta": {
        "l0": 0.09000000000000008,
        "l1": 0.134
      },
      "prefix_accuracy": {
        "j1_l0": 0.932,
        "j1_l1": 0.828,
        "j2_l0": 0.924,
        "j2_l1": 0.83,
        "j3_l0": 0.93,
        "j3_l1": 0.824,
        "j4_l0": 0.924,
        "j4_l1": 0.832
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.205313440026908,
          "loss_full": 3.7287397331204906,
          "loss_mrl": 4.127622698093282,
          "l0_accuracy": 0.8395989974937343,
          "l1_accuracy": 0.6992481203007519
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.8570427121787234,
          "loss_full": 2.309053800023835,
          "loss_mrl": 2.5799814187247176,
          "l0_accuracy": 0.8471177944862155,
          "l1_accuracy": 0.7230576441102757
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.8203402745312656,
          "loss_full": 1.6853751671725306,
          "loss_mrl": 1.8916084421092065,
          "l0_accuracy": 0.8483709273182958,
          "l1_accuracy": 0.7406015037593985
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.189259084545333,
          "loss_full": 1.3113779918900852,
          "loss_mrl": 1.4631350823517504,
          "l0_accuracy": 0.87468671679198,
          "l1_accuracy": 0.7669172932330827
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 1.6883908514318795,
          "loss_full": 1.0043228489571605,
          "loss_mrl": 1.140113299468468,
          "l0_accuracy": 0.8709273182957393,
          "l1_accuracy": 0.7656641604010025
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "123": {
      "method": "mrl_baseline",
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "mrl": {
        "l0_accuracy": 0.936,
        "l1_accuracy": 0.818
      },
      "delta": {
        "l0": 0.10200000000000009,
        "l1": 0.12
      },
      "prefix_accuracy": {
        "j1_l0": 0.942,
        "j1_l1": 0.816,
        "j2_l0": 0.94,
        "j2_l1": 0.814,
        "j3_l0": 0.936,
        "j3_l1": 0.822,
        "j4_l0": 0.936,
        "j4_l1": 0.818
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.140283989084178,
          "loss_full": 3.683970831180441,
          "loss_mrl": 4.0938551047752645,
          "l0_accuracy": 0.8333333333333334,
          "l1_accuracy": 0.6942355889724311
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.861596885220758,
          "loss_full": 2.296731692963633,
          "loss_mrl": 2.6081085270848767,
          "l0_accuracy": 0.8421052631578947,
          "l1_accuracy": 0.7243107769423559
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.8989959642804903,
          "loss_full": 1.7273286618035415,
          "loss_mrl": 1.9527787594959654,
          "l0_accuracy": 0.8421052631578947,
          "l1_accuracy": 0.7393483709273183
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.144260176296892,
          "loss_full": 1.2721078843906009,
          "loss_mrl": 1.4535870917912188,
          "l0_accuracy": 0.8508771929824561,
          "l1_accuracy": 0.7468671679197995
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 1.7251975322591848,
          "loss_full": 1.0269908936886951,
          "loss_mrl": 1.163677685219666,
          "l0_accuracy": 0.8483709273182958,
          "l1_accuracy": 0.7343358395989975
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "456": {
      "method": "mrl_baseline",
      "model": "qwen3-0.6b",
      "dataset": "trec",
      "baseline": {
        "l0_accuracy": 0.834,
        "l1_accuracy": 0.698
      },
      "mrl": {
        "l0_accuracy": 0.926,
        "l1_accuracy": 0.832
      },
      "delta": {
        "l0": 0.09200000000000008,
        "l1": 0.134
      },
      "prefix_accuracy": {
        "j1_l0": 0.94,
        "j1_l1": 0.834,
        "j2_l0": 0.938,
        "j2_l1": 0.832,
        "j3_l0": 0.934,
        "j3_l1": 0.838,
        "j4_l0": 0.926,
        "j4_l1": 0.832
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.184512957211198,
          "loss_full": 3.6886502089171573,
          "loss_mrl": 4.159771059299337,
          "l0_accuracy": 0.8220551378446115,
          "l1_accuracy": 0.6992481203007519
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 3.8611882139896525,
          "loss_full": 2.2870775987362038,
          "loss_mrl": 2.6235175864449864,
          "l0_accuracy": 0.8446115288220551,
          "l1_accuracy": 0.7180451127819549
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 2.8916374946462695,
          "loss_full": 1.713557143663538,
          "loss_mrl": 1.9634671605866532,
          "l0_accuracy": 0.8621553884711779,
          "l1_accuracy": 0.7543859649122807
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 2.193443017170347,
          "loss_full": 1.301294275193379,
          "loss_mrl": 1.4869145023411718,
          "l0_accuracy": 0.8609022556390977,
          "l1_accuracy": 0.7631578947368421
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 1.7710974744681653,
          "loss_full": 1.051839987676719,
          "loss_mrl": 1.1987624271162625,
          "l0_accuracy": 0.8696741854636592,
          "l1_accuracy": 0.7619047619047619
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    }
  }
}