{
  "model": "bge-small",
  "dataset": "yahoo",
  "seeds": [
    42,
    123,
    456,
    789,
    1024
  ],
  "v5": {
    "42": {
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "v5": {
        "l0_accuracy": 0.6935,
        "l1_accuracy": 0.6065
      },
      "delta": {
        "l0": 0.006000000000000005,
        "l1": 0.0040000000000000036
      },
      "prefix_accuracy": {
        "j1_l0": 0.674,
        "j1_l1": 0.586,
        "j2_l0": 0.68,
        "j2_l1": 0.598,
        "j3_l0": 0.688,
        "j3_l1": 0.612,
        "j4_l0": 0.69,
        "j4_l1": 0.618
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.112872609552348,
          "loss_full": 4.522889935295537,
          "loss_prefix": 4.316637656373798,
          "l0_accuracy": 0.792,
          "l1_accuracy": 0.78
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.424105924930212,
          "loss_full": 3.9937691589571394,
          "loss_prefix": 4.050561093384365,
          "l0_accuracy": 0.778,
          "l1_accuracy": 0.766
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.203873571359886,
          "loss_full": 3.8394377609468857,
          "loss_prefix": 3.9407261938418983,
          "l0_accuracy": 0.76,
          "l1_accuracy": 0.742
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 6.085962770569999,
          "loss_full": 3.769011640548706,
          "loss_prefix": 3.8615850430614542,
          "l0_accuracy": 0.772,
          "l1_accuracy": 0.754
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 6.006319733385769,
          "loss_full": 3.714412542559066,
          "loss_prefix": 3.819845159098787,
          "l0_accuracy": 0.771,
          "l1_accuracy": 0.761
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "123": {
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "v5": {
        "l0_accuracy": 0.71,
        "l1_accuracy": 0.6315
      },
      "delta": {
        "l0": 0.022499999999999964,
        "l1": 0.028999999999999915
      },
      "prefix_accuracy": {
        "j1_l0": 0.7,
        "j1_l1": 0.614,
        "j2_l0": 0.71,
        "j2_l1": 0.64,
        "j3_l0": 0.718,
        "j3_l1": 0.65,
        "j4_l0": 0.724,
        "j4_l1": 0.658
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.14824745250198,
          "loss_full": 4.534680074115969,
          "loss_prefix": 4.35594549448985,
          "l0_accuracy": 0.759,
          "l1_accuracy": 0.752
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.4201468629657095,
          "loss_full": 3.9940214678926287,
          "loss_prefix": 4.043542157479052,
          "l0_accuracy": 0.765,
          "l1_accuracy": 0.759
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.224800935781227,
          "loss_full": 3.849885371945939,
          "loss_prefix": 3.9581924609418184,
          "l0_accuracy": 0.775,
          "l1_accuracy": 0.761
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 6.111511871049989,
          "loss_full": 3.788844368592748,
          "loss_prefix": 3.8711123367525495,
          "l0_accuracy": 0.771,
          "l1_accuracy": 0.758
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 5.982035732269287,
          "loss_full": 3.690581982990481,
          "loss_prefix": 3.8190894261846005,
          "l0_accuracy": 0.783,
          "l1_accuracy": 0.764
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "456": {
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "v5": {
        "l0_accuracy": 0.6985,
        "l1_accuracy": 0.617
      },
      "delta": {
        "l0": 0.01100000000000001,
        "l1": 0.014499999999999957
      },
      "prefix_accuracy": {
        "j1_l0": 0.702,
        "j1_l1": 0.638,
        "j2_l0": 0.7,
        "j2_l1": 0.638,
        "j3_l0": 0.7,
        "j3_l1": 0.626,
        "j4_l0": 0.702,
        "j4_l1": 0.634
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.110794731356063,
          "loss_full": 4.511091491411317,
          "loss_prefix": 4.332838592889174,
          "l0_accuracy": 0.768,
          "l1_accuracy": 0.756
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.4169499703173365,
          "loss_full": 4.002481267137347,
          "loss_prefix": 4.024114335258052,
          "l0_accuracy": 0.769,
          "l1_accuracy": 0.753
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.200402225638336,
          "loss_full": 3.842749258257308,
          "loss_prefix": 3.929421456354969,
          "l0_accuracy": 0.769,
          "l1_accuracy": 0.762
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 6.094538708452909,
          "loss_full": 3.7709502229150735,
          "loss_prefix": 3.8726472782638837,
          "l0_accuracy": 0.782,
          "l1_accuracy": 0.761
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 5.987711665315448,
          "loss_full": 3.696738255698726,
          "loss_prefix": 3.8182888516839943,
          "l0_accuracy": 0.778,
          "l1_accuracy": 0.76
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "789": {
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "v5": {
        "l0_accuracy": 0.6825,
        "l1_accuracy": 0.6055
      },
      "delta": {
        "l0": -0.0050000000000000044,
        "l1": 0.0030000000000000027
      },
      "prefix_accuracy": {
        "j1_l0": 0.678,
        "j1_l1": 0.596,
        "j2_l0": 0.666,
        "j2_l1": 0.604,
        "j3_l0": 0.68,
        "j3_l1": 0.598,
        "j4_l0": 0.698,
        "j4_l1": 0.614
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.904780697238872,
          "loss_full": 3.748024371159728,
          "loss_prefix": 3.5945937314724965,
          "l0_accuracy": 0.789,
          "l1_accuracy": 0.783
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.295848256450588,
          "loss_full": 3.304986272603554,
          "loss_prefix": 3.3181031675213024,
          "l0_accuracy": 0.77,
          "l1_accuracy": 0.758
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.09901829403448,
          "loss_full": 3.16453880644114,
          "loss_prefix": 3.224132351956125,
          "l0_accuracy": 0.767,
          "l1_accuracy": 0.757
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.015538624675485,
          "loss_full": 3.1079321123112393,
          "loss_prefix": 3.1793440742007757,
          "l0_accuracy": 0.772,
          "l1_accuracy": 0.761
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.913813679905261,
          "loss_full": 3.0416361082296137,
          "loss_prefix": 3.120295817344651,
          "l0_accuracy": 0.766,
          "l1_accuracy": 0.76
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "1024": {
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "v5": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6165
      },
      "delta": {
        "l0": 0.0,
        "l1": 0.014000000000000012
      },
      "prefix_accuracy": {
        "j1_l0": 0.668,
        "j1_l1": 0.564,
        "j2_l0": 0.674,
        "j2_l1": 0.614,
        "j3_l0": 0.674,
        "j3_l1": 0.624,
        "j4_l0": 0.682,
        "j4_l1": 0.622
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.928879380450635,
          "loss_full": 3.7549540174882963,
          "loss_prefix": 3.62320878950216,
          "l0_accuracy": 0.77,
          "l1_accuracy": 0.763
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.292238270046572,
          "loss_full": 3.285890163899366,
          "loss_prefix": 3.3439133970975425,
          "l0_accuracy": 0.779,
          "l1_accuracy": 0.773
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.108753991441314,
          "loss_full": 3.167825189238439,
          "loss_prefix": 3.2348812214623286,
          "l0_accuracy": 0.772,
          "l1_accuracy": 0.771
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.017773409572249,
          "loss_full": 3.12319172236879,
          "loss_prefix": 3.1576360093671725,
          "l0_accuracy": 0.768,
          "l1_accuracy": 0.759
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.936870243140758,
          "loss_full": 3.0588146023831126,
          "loss_prefix": 3.130092604236639,
          "l0_accuracy": 0.776,
          "l1_accuracy": 0.765
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    }
  },
  "mrl": {
    "42": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "mrl": {
        "l0_accuracy": 0.7105,
        "l1_accuracy": 0.629
      },
      "delta": {
        "l0": 0.02300000000000002,
        "l1": 0.026499999999999968
      },
      "prefix_accuracy": {
        "j1_l0": 0.7,
        "j1_l1": 0.644,
        "j2_l0": 0.708,
        "j2_l1": 0.654,
        "j3_l0": 0.702,
        "j3_l1": 0.632,
        "j4_l0": 0.702,
        "j4_l1": 0.636
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.247908950301836,
          "loss_full": 4.500596172404739,
          "loss_mrl": 4.5788544690833906,
          "l0_accuracy": 0.765,
          "l1_accuracy": 0.754
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.342269942445575,
          "loss_full": 3.976226979381633,
          "loss_mrl": 3.9434047600008406,
          "l0_accuracy": 0.778,
          "l1_accuracy": 0.768
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.097877399876433,
          "loss_full": 3.8238794731643964,
          "loss_mrl": 3.7899963909724974,
          "l0_accuracy": 0.782,
          "l1_accuracy": 0.769
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.971381946779647,
          "loss_full": 3.746628677620078,
          "loss_mrl": 3.7079219494225844,
          "l0_accuracy": 0.777,
          "l1_accuracy": 0.771
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 5.888468618213006,
          "loss_full": 3.694556564654944,
          "loss_mrl": 3.6565199537097284,
          "l0_accuracy": 0.761,
          "l1_accuracy": 0.754
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "123": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "mrl": {
        "l0_accuracy": 0.687,
        "l1_accuracy": 0.6215
      },
      "delta": {
        "l0": -0.0004999999999999449,
        "l1": 0.019000000000000017
      },
      "prefix_accuracy": {
        "j1_l0": 0.704,
        "j1_l1": 0.628,
        "j2_l0": 0.716,
        "j2_l1": 0.636,
        "j3_l0": 0.698,
        "j3_l1": 0.62,
        "j4_l0": 0.694,
        "j4_l1": 0.634
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.281876150167213,
          "loss_full": 4.521502965351321,
          "loss_mrl": 4.600621783058599,
          "l0_accuracy": 0.772,
          "l1_accuracy": 0.762
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.359314956305162,
          "loss_full": 3.9845999285859883,
          "loss_mrl": 3.9578582196865444,
          "l0_accuracy": 0.765,
          "l1_accuracy": 0.747
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.10480792207538,
          "loss_full": 3.8290113089219577,
          "loss_mrl": 3.792994178016231,
          "l0_accuracy": 0.768,
          "l1_accuracy": 0.752
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.995699070984463,
          "loss_full": 3.7633708809906583,
          "loss_mrl": 3.7205468375727815,
          "l0_accuracy": 0.777,
          "l1_accuracy": 0.764
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 5.8713391178059124,
          "loss_full": 3.6819406554384053,
          "loss_mrl": 3.6489973104225015,
          "l0_accuracy": 0.767,
          "l1_accuracy": 0.756
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "456": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "mrl": {
        "l0_accuracy": 0.6945,
        "l1_accuracy": 0.6135
      },
      "delta": {
        "l0": 0.007000000000000006,
        "l1": 0.01100000000000001
      },
      "prefix_accuracy": {
        "j1_l0": 0.704,
        "j1_l1": 0.64,
        "j2_l0": 0.706,
        "j2_l1": 0.648,
        "j3_l0": 0.708,
        "j3_l1": 0.658,
        "j4_l0": 0.7,
        "j4_l1": 0.642
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.29228617650158,
          "loss_full": 4.520552137662779,
          "loss_mrl": 4.619556608739889,
          "l0_accuracy": 0.761,
          "l1_accuracy": 0.747
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 6.38182879573894,
          "loss_full": 3.99678939063594,
          "loss_mrl": 3.9750655084286097,
          "l0_accuracy": 0.769,
          "l1_accuracy": 0.755
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 6.116386516139192,
          "loss_full": 3.831696964659781,
          "loss_mrl": 3.807815747890832,
          "l0_accuracy": 0.763,
          "l1_accuracy": 0.753
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.991386440565002,
          "loss_full": 3.7643364699381703,
          "loss_mrl": 3.711749802895312,
          "l0_accuracy": 0.783,
          "l1_accuracy": 0.768
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 5.8827582575240225,
          "loss_full": 3.692901331523679,
          "loss_mrl": 3.649761373591873,
          "l0_accuracy": 0.774,
          "l1_accuracy": 0.767
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "789": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "mrl": {
        "l0_accuracy": 0.6825,
        "l1_accuracy": 0.6145
      },
      "delta": {
        "l0": -0.0050000000000000044,
        "l1": 0.01200000000000001
      },
      "prefix_accuracy": {
        "j1_l0": 0.692,
        "j1_l1": 0.616,
        "j2_l0": 0.682,
        "j2_l1": 0.612,
        "j3_l0": 0.682,
        "j3_l1": 0.616,
        "j4_l0": 0.68,
        "j4_l1": 0.62
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.023041551395998,
          "loss_full": 3.7472019680475785,
          "loss_mrl": 3.793065816444641,
          "l0_accuracy": 0.775,
          "l1_accuracy": 0.768
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.228054655922784,
          "loss_full": 3.285772093271805,
          "loss_mrl": 3.237137478399187,
          "l0_accuracy": 0.783,
          "l1_accuracy": 0.773
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.025674969463025,
          "loss_full": 3.1573627455310858,
          "loss_mrl": 3.1138535816566195,
          "l0_accuracy": 0.783,
          "l1_accuracy": 0.773
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.912223656972249,
          "loss_full": 3.0919243865093944,
          "loss_mrl": 3.033831984085327,
          "l0_accuracy": 0.766,
          "l1_accuracy": 0.757
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.810552398588249,
          "loss_full": 3.0192344731979226,
          "loss_mrl": 2.9855297487334345,
          "l0_accuracy": 0.769,
          "l1_accuracy": 0.759
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "1024": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "yahoo",
      "baseline": {
        "l0_accuracy": 0.6875,
        "l1_accuracy": 0.6025
      },
      "mrl": {
        "l0_accuracy": 0.681,
        "l1_accuracy": 0.607
      },
      "delta": {
        "l0": -0.00649999999999995,
        "l1": 0.0044999999999999485
      },
      "prefix_accuracy": {
        "j1_l0": 0.72,
        "j1_l1": 0.65,
        "j2_l0": 0.712,
        "j2_l1": 0.646,
        "j3_l0": 0.708,
        "j3_l1": 0.638,
        "j4_l0": 0.714,
        "j4_l1": 0.642
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.043760084611997,
          "loss_full": 3.755009672736044,
          "loss_mrl": 3.8145838690791876,
          "l0_accuracy": 0.76,
          "l1_accuracy": 0.743
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.230429972632456,
          "loss_full": 3.2872176848337924,
          "loss_mrl": 3.238687006093688,
          "l0_accuracy": 0.761,
          "l1_accuracy": 0.749
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.029907755483566,
          "loss_full": 3.157175877448978,
          "loss_mrl": 3.121219661500719,
          "l0_accuracy": 0.773,
          "l1_accuracy": 0.763
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.901252935610698,
          "loss_full": 3.0800449199371194,
          "loss_mrl": 3.035346579416997,
          "l0_accuracy": 0.756,
          "l1_accuracy": 0.743
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.827573420188746,
          "loss_full": 3.0399442484598826,
          "loss_mrl": 2.97938185402678,
          "l0_accuracy": 0.768,
          "l1_accuracy": 0.748
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    }
  }
}