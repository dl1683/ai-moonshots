{
  "model": "bge-small",
  "dataset": "newsgroups",
  "seeds": [
    42,
    123,
    456,
    789,
    1024
  ],
  "v5": {
    "42": {
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "v5": {
        "l0_accuracy": 0.807,
        "l1_accuracy": 0.661
      },
      "delta": {
        "l0": -0.007999999999999896,
        "l1": 0.0030000000000000027
      },
      "prefix_accuracy": {
        "j1_l0": 0.788,
        "j1_l1": 0.574,
        "j2_l0": 0.792,
        "j2_l1": 0.632,
        "j3_l0": 0.798,
        "j3_l1": 0.628,
        "j4_l0": 0.802,
        "j4_l1": 0.628
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.643464283835619,
          "loss_full": 4.313211098649448,
          "loss_prefix": 3.8837551425274155,
          "l0_accuracy": 0.773,
          "l1_accuracy": 0.607
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.560022275250657,
          "loss_full": 3.5045364539426074,
          "loss_prefix": 3.4258095823732533,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.638
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.200132281260383,
          "loss_full": 3.2342785740257205,
          "loss_prefix": 3.2764227085543753,
          "l0_accuracy": 0.816,
          "l1_accuracy": 0.676
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.009947197777884,
          "loss_full": 3.1088035043917204,
          "loss_prefix": 3.1685727135579387,
          "l0_accuracy": 0.802,
          "l1_accuracy": 0.677
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.816188030673149,
          "loss_full": 2.9631245566490003,
          "loss_prefix": 3.088439018206489,
          "l0_accuracy": 0.803,
          "l1_accuracy": 0.683
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "123": {
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "v5": {
        "l0_accuracy": 0.798,
        "l1_accuracy": 0.65
      },
      "delta": {
        "l0": -0.016999999999999904,
        "l1": -0.008000000000000007
      },
      "prefix_accuracy": {
        "j1_l0": 0.784,
        "j1_l1": 0.62,
        "j2_l0": 0.808,
        "j2_l1": 0.656,
        "j3_l0": 0.804,
        "j3_l1": 0.646,
        "j4_l0": 0.808,
        "j4_l1": 0.632
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.649696394913178,
          "loss_full": 4.3570682751505,
          "loss_prefix": 3.821046715392206,
          "l0_accuracy": 0.769,
          "l1_accuracy": 0.605
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.558180920163491,
          "loss_full": 3.513648503705075,
          "loss_prefix": 3.4075538681862048,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.642
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.213347542554812,
          "loss_full": 3.2625705604266404,
          "loss_prefix": 3.2512948369621335,
          "l0_accuracy": 0.801,
          "l1_accuracy": 0.674
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 5.016157478318179,
          "loss_full": 3.113126712634151,
          "loss_prefix": 3.1717178391334704,
          "l0_accuracy": 0.812,
          "l1_accuracy": 0.686
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.839221430900402,
          "loss_full": 2.975807213245478,
          "loss_prefix": 3.1056902292079496,
          "l0_accuracy": 0.802,
          "l1_accuracy": 0.683
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "456": {
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "v5": {
        "l0_accuracy": 0.799,
        "l1_accuracy": 0.6595
      },
      "delta": {
        "l0": -0.015999999999999903,
        "l1": 0.0014999999999999458
      },
      "prefix_accuracy": {
        "j1_l0": 0.794,
        "j1_l1": 0.606,
        "j2_l0": 0.798,
        "j2_l1": 0.656,
        "j3_l0": 0.81,
        "j3_l1": 0.662,
        "j4_l0": 0.814,
        "j4_l1": 0.664
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 6.641364336013794,
          "loss_full": 4.343463042624911,
          "loss_prefix": 3.8298353144997046,
          "l0_accuracy": 0.782,
          "l1_accuracy": 0.624
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.559061880398514,
          "loss_full": 3.5124128196472513,
          "loss_prefix": 3.41108164661809,
          "l0_accuracy": 0.789,
          "l1_accuracy": 0.647
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.204119166037194,
          "loss_full": 3.2342184253205035,
          "loss_prefix": 3.2831677897532185,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.652
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.996023558136216,
          "loss_full": 3.103930952853726,
          "loss_prefix": 3.1534875353476157,
          "l0_accuracy": 0.804,
          "l1_accuracy": 0.681
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.8339079985941265,
          "loss_full": 2.9757898427490006,
          "loss_prefix": 3.096863466097896,
          "l0_accuracy": 0.816,
          "l1_accuracy": 0.693
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "789": {
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "v5": {
        "l0_accuracy": 0.79,
        "l1_accuracy": 0.6555
      },
      "delta": {
        "l0": -0.02499999999999991,
        "l1": -0.0025000000000000577
      },
      "prefix_accuracy": {
        "j1_l0": 0.802,
        "j1_l1": 0.604,
        "j2_l0": 0.802,
        "j2_l1": 0.618,
        "j3_l0": 0.788,
        "j3_l1": 0.626,
        "j4_l0": 0.784,
        "j4_l1": 0.63
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.4064655599737526,
          "loss_full": 3.54904685298303,
          "loss_prefix": 3.095697710612663,
          "l0_accuracy": 0.79,
          "l1_accuracy": 0.643
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 4.420099659073622,
          "loss_full": 2.81386137008667,
          "loss_prefix": 2.6770637205668857,
          "l0_accuracy": 0.797,
          "l1_accuracy": 0.659
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 4.095076753680868,
          "loss_full": 2.5689033897299516,
          "loss_prefix": 2.5436221780185413,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.665
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 3.9129076488035963,
          "loss_full": 2.4329325072747423,
          "loss_prefix": 2.4666251399015127,
          "l0_accuracy": 0.794,
          "l1_accuracy": 0.669
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 3.7512098801763436,
          "loss_full": 2.3214452896351205,
          "loss_prefix": 2.382940893558631,
          "l0_accuracy": 0.797,
          "l1_accuracy": 0.677
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    },
    "1024": {
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "v5": {
        "l0_accuracy": 0.7985,
        "l1_accuracy": 0.649
      },
      "delta": {
        "l0": -0.01649999999999996,
        "l1": -0.009000000000000008
      },
      "prefix_accuracy": {
        "j1_l0": 0.804,
        "j1_l1": 0.576,
        "j2_l0": 0.784,
        "j2_l1": 0.63,
        "j3_l0": 0.79,
        "j3_l1": 0.64,
        "j4_l0": 0.804,
        "j4_l1": 0.642
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.432415743519489,
          "loss_full": 3.577229858789229,
          "loss_prefix": 3.0919763488428935,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.649
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 4.445406277825062,
          "loss_full": 2.8379254872189428,
          "loss_prefix": 2.6791345409880902,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.659
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 4.110824445136507,
          "loss_full": 2.576697148102567,
          "loss_prefix": 2.5568787202351073,
          "l0_accuracy": 0.805,
          "l1_accuracy": 0.666
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 3.917664115142105,
          "loss_full": 2.4340542389037916,
          "loss_prefix": 2.4726830140540472,
          "l0_accuracy": 0.802,
          "l1_accuracy": 0.679
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 3.7735705389116045,
          "loss_full": 2.334961190483624,
          "loss_prefix": 2.3976821525204453,
          "l0_accuracy": 0.815,
          "l1_accuracy": 0.706
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "prefix_weight": 0.6
      }
    }
  },
  "mrl": {
    "42": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "mrl": {
        "l0_accuracy": 0.81,
        "l1_accuracy": 0.668
      },
      "delta": {
        "l0": -0.004999999999999893,
        "l1": 0.010000000000000009
      },
      "prefix_accuracy": {
        "j1_l0": 0.796,
        "j1_l1": 0.654,
        "j2_l0": 0.806,
        "j2_l1": 0.648,
        "j3_l0": 0.79,
        "j3_l1": 0.644,
        "j4_l0": 0.796,
        "j4_l1": 0.652
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.07349843907177,
          "loss_full": 4.3425034508669285,
          "loss_mrl": 4.551658152637625,
          "l0_accuracy": 0.77,
          "l1_accuracy": 0.622
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.67177146718018,
          "loss_full": 3.522882880124831,
          "loss_mrl": 3.5814808114130696,
          "l0_accuracy": 0.782,
          "l1_accuracy": 0.651
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.173179164864963,
          "loss_full": 3.22346586213076,
          "loss_mrl": 3.249522060379946,
          "l0_accuracy": 0.798,
          "l1_accuracy": 0.669
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.878857307864311,
          "loss_full": 3.045592975795717,
          "loss_mrl": 3.055440440661925,
          "l0_accuracy": 0.801,
          "l1_accuracy": 0.682
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.658721350189438,
          "loss_full": 2.9120500320778753,
          "loss_mrl": 2.9111187561114034,
          "l0_accuracy": 0.806,
          "l1_accuracy": 0.694
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "123": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "mrl": {
        "l0_accuracy": 0.7945,
        "l1_accuracy": 0.6645
      },
      "delta": {
        "l0": -0.020499999999999963,
        "l1": 0.00649999999999995
      },
      "prefix_accuracy": {
        "j1_l0": 0.812,
        "j1_l1": 0.634,
        "j2_l0": 0.796,
        "j2_l1": 0.64,
        "j3_l0": 0.8,
        "j3_l1": 0.652,
        "j4_l0": 0.806,
        "j4_l1": 0.65
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.145984608427923,
          "loss_full": 4.371904852695035,
          "loss_mrl": 4.623466086566896,
          "l0_accuracy": 0.777,
          "l1_accuracy": 0.63
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.651647067607794,
          "loss_full": 3.503635183312839,
          "loss_mrl": 3.5800196586694932,
          "l0_accuracy": 0.795,
          "l1_accuracy": 0.656
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.199268526600716,
          "loss_full": 3.2428196319063805,
          "loss_mrl": 3.260748018895773,
          "l0_accuracy": 0.811,
          "l1_accuracy": 0.694
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.899157942685866,
          "loss_full": 3.0488515070506503,
          "loss_mrl": 3.0838439285307,
          "l0_accuracy": 0.817,
          "l1_accuracy": 0.689
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.681187839436352,
          "loss_full": 2.918930911928191,
          "loss_mrl": 2.937094760120363,
          "l0_accuracy": 0.816,
          "l1_accuracy": 0.691
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "456": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "mrl": {
        "l0_accuracy": 0.799,
        "l1_accuracy": 0.6605
      },
      "delta": {
        "l0": -0.015999999999999903,
        "l1": 0.0024999999999999467
      },
      "prefix_accuracy": {
        "j1_l0": 0.8,
        "j1_l1": 0.648,
        "j2_l0": 0.8,
        "j2_l1": 0.652,
        "j3_l0": 0.792,
        "j3_l1": 0.644,
        "j4_l0": 0.79,
        "j4_l1": 0.646
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 7.153483894534577,
          "loss_full": 4.3969330357429675,
          "loss_mrl": 4.594251236521211,
          "l0_accuracy": 0.771,
          "l1_accuracy": 0.615
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 5.6355667956789635,
          "loss_full": 3.492790292080184,
          "loss_mrl": 3.571294009237361,
          "l0_accuracy": 0.792,
          "l1_accuracy": 0.636
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 5.174610205162737,
          "loss_full": 3.220222666747588,
          "loss_mrl": 3.2573124313713016,
          "l0_accuracy": 0.803,
          "l1_accuracy": 0.68
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 4.944579209600176,
          "loss_full": 3.0903799695179877,
          "loss_mrl": 3.0903319205556596,
          "l0_accuracy": 0.805,
          "l1_accuracy": 0.68
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 4.684413043179906,
          "loss_full": 2.921136496658612,
          "loss_mrl": 2.938794137839984,
          "l0_accuracy": 0.817,
          "l1_accuracy": 0.693
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 32,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "789": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "mrl": {
        "l0_accuracy": 0.793,
        "l1_accuracy": 0.647
      },
      "delta": {
        "l0": -0.02199999999999991,
        "l1": -0.01100000000000001
      },
      "prefix_accuracy": {
        "j1_l0": 0.798,
        "j1_l1": 0.652,
        "j2_l0": 0.812,
        "j2_l1": 0.656,
        "j3_l0": 0.806,
        "j3_l1": 0.656,
        "j4_l0": 0.81,
        "j4_l1": 0.646
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.7941054701805115,
          "loss_full": 3.5686477221044384,
          "loss_mrl": 3.7090960969602254,
          "l0_accuracy": 0.788,
          "l1_accuracy": 0.636
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 4.517651504591892,
          "loss_full": 2.8194891140425113,
          "loss_mrl": 2.830270536636051,
          "l0_accuracy": 0.784,
          "l1_accuracy": 0.651
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 4.082127941058094,
          "loss_full": 2.549236002497207,
          "loss_mrl": 2.554819796542476,
          "l0_accuracy": 0.796,
          "l1_accuracy": 0.671
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 3.858164573970594,
          "loss_full": 2.415995765001254,
          "loss_mrl": 2.4036145853368858,
          "l0_accuracy": 0.798,
          "l1_accuracy": 0.673
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 3.644351245765399,
          "loss_full": 2.2891956936371955,
          "loss_mrl": 2.258592504083662,
          "l0_accuracy": 0.807,
          "l1_accuracy": 0.694
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    },
    "1024": {
      "method": "mrl_baseline",
      "model": "bge-small",
      "dataset": "newsgroups",
      "baseline": {
        "l0_accuracy": 0.815,
        "l1_accuracy": 0.658
      },
      "mrl": {
        "l0_accuracy": 0.797,
        "l1_accuracy": 0.662
      },
      "delta": {
        "l0": -0.017999999999999905,
        "l1": 0.0040000000000000036
      },
      "prefix_accuracy": {
        "j1_l0": 0.788,
        "j1_l1": 0.656,
        "j2_l0": 0.788,
        "j2_l1": 0.656,
        "j3_l0": 0.79,
        "j3_l1": 0.658,
        "j4_l0": 0.798,
        "j4_l1": 0.656
      },
      "history": [
        {
          "stage": 1,
          "epoch": 1,
          "loss": 5.763371671949114,
          "loss_full": 3.538505150411362,
          "loss_mrl": 3.7081107192469718,
          "l0_accuracy": 0.772,
          "l1_accuracy": 0.612
        },
        {
          "stage": 1,
          "epoch": 2,
          "loss": 4.487259248593696,
          "loss_full": 2.798406299119605,
          "loss_mrl": 2.8147548069631245,
          "l0_accuracy": 0.805,
          "l1_accuracy": 0.668
        },
        {
          "stage": 1,
          "epoch": 3,
          "loss": 4.054152052205308,
          "loss_full": 2.5363788994631373,
          "loss_mrl": 2.52962181375439,
          "l0_accuracy": 0.805,
          "l1_accuracy": 0.678
        },
        {
          "stage": 1,
          "epoch": 4,
          "loss": 3.839702650568539,
          "loss_full": 2.407382400188231,
          "loss_mrl": 2.3872003149717376,
          "l0_accuracy": 0.808,
          "l1_accuracy": 0.701
        },
        {
          "stage": 1,
          "epoch": 5,
          "loss": 3.6480468565360047,
          "loss_full": 2.281787161988423,
          "loss_mrl": 2.277099410170003,
          "l0_accuracy": 0.811,
          "l1_accuracy": 0.691
        }
      ],
      "training_config": {
        "prefix_probs": [
          0.4,
          0.3,
          0.2,
          0.1
        ],
        "block_keep_probs": [
          0.95,
          0.9,
          0.8,
          0.7
        ],
        "mrl_weight": 0.6,
        "margin_weight": 0.5,
        "class_weight": 1.0,
        "stage1_epochs": 5,
        "stage2_epochs": 0,
        "batch_size": 16,
        "lr": 0.0001,
        "weight_decay": 0.01,
        "temperature": 0.07,
        "grad_clip": 1.0,
        "note": "num_l0_classes set to num_l1_classes so head_top outputs L1 logits"
      }
    }
  }
}